---
title: "Final Project. @mmblanes"
author: "Manuel Martínez Blanes"
date: "24 de marzo de 2016"
output: html_document
---

******

#### In this step of the course, an n-gram model has been built to predicting the next word from the previous words.

#### Objetives

* Build a shiny application that is able to predict the next word.  
* A corpus has been created from [(Corpus Data Source)](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip) for this project. 
* The next R packages that have been used for text mining and natural language processing, have been:tm, slam, stringr, RWeka and parallel

******

#### Applied methods and models


After a Corpus generated, then following clean up steps are performed.  
  
  * Convert all words to lowercase
  * Remove URL and special characters
  * Eliminate numbers, punctuation, dashs and apostroples
  * Strip whitespace, and Trim leading and trailing whitespace

This sampled corpus was then used to creat Bigram, Trigram, Quadgram and Quintgram.

When an user input text, up to last 4 words will be used to predict the next word accroding to the frequencies of the underlying *N-Grams*. 

Stupid Backoff Algorithm has been implemented as following formula:

Total_prob = 1*Quintgrams_prob + 0.4*Quadgrams_prob + 0.16*Trigrams_prob + 0.064*Bigrams_prob 

******

#### How to use

Mobile users are targeted by this light-weighted application. While entering the text, the predicted next word will be shown instantaneously. And how many words and characters the user just has entered will be displayed too (see screen shot below).

![Application Screenshot](screenMB.png)

******



#### Links

* The scripts related to this shiny application, as well as the milestone report and the capstone project presentation (link) can be found in [this GitHub repository](https://github.com/mmblanes/Capstone/tree/master).
